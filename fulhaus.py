# -*- coding: utf-8 -*-
"""Fulhaus.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-W6unv6WYn1jGFL9otzkQjPz3LJS2P8J

## Pre-Processing Data
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow.keras import models, layers

print(tf.__version__)

import pickle

import urllib.request

df = pd.read_csv("DS4.csv")

#df= df.sample(frac=1)

y = df.iloc[:,0]

Y = {1:"bed",2:"chair",3:"sofa"}

x = df.iloc[:,1]

X=[]
for i in x:
  i=i.split(" ")
  i=i[:-1]
  t = [int(j) for j in i]
  X.append(t)

X=np.array(X)

X.shape

y=np.array(y)

y.shape

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X ,y)

X_train

train_images= []

for i in X_train:
  train_images.append(i.reshape(32,32,3))

train_images=np.array(train_images)

test_images= []

for i in X_test:
  test_images.append(i.reshape(32,32,3))

test_images=np.array(test_images)

plt.figure(figsize=(10,10))

for i in range(25):
  plt.subplot(5,5, i+1)
  plt.imshow(train_images[i])
  plt.xticks([])
  plt.xlabel(Y[y_train[i]])
plt.show()

"""## Model"""

model = models.Sequential()

model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)))
model.add(layers.MaxPooling2D(2,2))

model.add(layers.Conv2D(64, (3,3), activation='relu'))
model.add(layers.MaxPooling2D(2,2))

model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10))

model.summary()

model.compile(optimizer='adam',
             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
             metrics=['accuracy'])

history = model.fit(train_images, y_train,
                    epochs=10,
                    validation_data=(test_images,y_test))

test_loss, test_accuracy= model.evaluate(test_images, y_test)
test_loss, test_accuracy

#pickle.dump(history, open('model.pkl', 'wb'))

import joblib

joblib.dump(model, "model.pkl")

"""##Getting Prediction Using image Link"""

def get_prediction(link):
  urllib.request.urlretrieve(link,"image.jpg")
  o = Image.open("image.jpg")
  o = o.resize((32, 32))
  o = o.convert('RGB')
  o_value = np.asarray(o.getdata(), dtype=np.int).reshape((32, 32, 3))
  o_value = o_value.flatten()
  o_value = o_value.reshape(-1,32,32,3)
  y_predict = np.argmax(model.predict(o_value), axis=-1)
  prediction = Y[y_predict[0]]

  return prediction

link=  'https://thumbs.dreamstime.com/b/comfortable-bed-white-background-idea-interior-design-136555161.jpg'
out = get_prediction(link)

print(out)

"""#Flask-Ngrok API"""

pip install flask-ngrok

pip install pyngrok

pip install flask

from flask import Flask, jsonify, request
from flask_ngrok import run_with_ngrok
import joblib
from pyngrok import ngrok
from PIL import Image

app = Flask(__name__)
model = joblib.load('model.pkl')

@app.route('/')
def home():
  return render_template('index.html')

@app.route('/classify', methods=['POST'])

def classify():
    
    image_file = request.files['image']
    o = Image.open(image_file).convert('RGB')
    o = o.resize((32, 32))
    o = o.convert('RGB')
    o_value = np.asarray(o.getdata(), dtype=np.int).reshape((32, 32, 3))
    o_value = o_value.flatten()
    o_value = o_value.reshape(-1,32,32,3)

    y_predict = np.argmax(model.predict(o_value), axis=-1)
    prediction = Y[y_predict[0]]  

    return jsonify({'class': prediction})

if __name__ == '__main__':
    public_url = ngrok.connect(port=5000).public_url
    print('Public URL:', public_url)
    debug(True)
    app.run(host='0.0.0.0', port='5000')